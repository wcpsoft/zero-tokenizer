#!/usr/bin/env python3
"""
Zero Tokenizer vs HuggingFace Tokenizers å®Œæ•´æ€§èƒ½å¯¹æ¯”åŸºå‡†æµ‹è¯•

æµ‹è¯•æ‰€æœ‰ç®—æ³•ï¼šBPEã€BBPEã€Unigramã€WordPiece
åŒ…å«ç‰¹æ€§ï¼šå­—å…¸åˆå§‹åŒ–ã€æ‰¹é‡ç¼–ç ã€è®­ç»ƒã€è§£ç 

è¿è¡Œæ–¹å¼ï¼š
    python benchmarks/compare_with_hf.py
    python benchmarks/compare_with_hf.py --algorithm all --vocab-size 5000
    python benchmarks/compare_with_hf.py --algorithm bpe --iterations 10
"""

import time
import argparse
import sys
from pathlib import Path
from typing import List, Dict, Optional
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "python"))

# å¯¼å…¥Zero Tokenizer
try:
    from zero_tokenizer import (
        BPETokenizer as ZeroBPE,
        BBPETokenizer as ZeroBBPE,
        UnigramTokenizer as ZeroUnigram,
        WordPieceTokenizer as ZeroWordPiece,
    )
    ZERO_AVAILABLE = True
except ImportError as e:
    print(f"âŒ Zero Tokenizeræœªå®‰è£…: {e}")
    print("   è¯·å…ˆè¿è¡Œ: maturin develop")
    ZERO_AVAILABLE = False

# å¯¼å…¥HuggingFace Tokenizers
try:
    from tokenizers import Tokenizer, models, trainers, pre_tokenizers
    HF_AVAILABLE = True
except ImportError:
    print("âš ï¸  HuggingFace tokenizersæœªå®‰è£…ï¼Œå°†è·³è¿‡HFæµ‹è¯•")
    print("   å®‰è£…å‘½ä»¤: pip install tokenizers")
    HF_AVAILABLE = False


class ComprehensiveBenchmark:
    """å®Œæ•´çš„æ€§èƒ½åŸºå‡†æµ‹è¯•ç±»"""

    # ç®—æ³•æ˜ å°„
    ALGORITHMS = {
        'bpe': 'BPE',
        'bbpe': 'BBPE (Byte-level BPE)',
        'unigram': 'Unigram',
        'wordpiece': 'WordPiece',
    }

    def __init__(self, algorithm: str = 'bpe', vocab_size: int = 1000, iterations: int = 5):
        self.algorithm = algorithm
        self.vocab_size = vocab_size
        self.iterations = iterations
        self.results = {}

        # æµ‹è¯•æ•°æ®é›†
        self.train_corpus = self._generate_corpus(500)
        self.test_texts = self._generate_corpus(100)

        # å­—å…¸è·¯å¾„
        self.dict_path = project_root / "dict" / "å¸¸ç”¨æ±‰å­—å­—è¡¨.txt"

    def _generate_corpus(self, size: int) -> List[str]:
        """ç”Ÿæˆæµ‹è¯•è¯­æ–™ï¼ˆåŒ…å«è‹±æ–‡å’Œä¸­æ–‡ï¼‰"""
        texts = [
            "The quick brown fox jumps over the lazy dog.",
            "Python is a high-level programming language.",
            "Machine learning models require large datasets.",
            "Natural language processing is fascinating.",
            "Tokenization is the first step in NLP pipelines.",
            "Performance optimization is crucial for production systems.",
            "Rust provides memory safety without garbage collection.",
            "Zero Tokenizer aims to match HuggingFace performance.",
            "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œã€‚",
            "æ·±åº¦å­¦ä¹ éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚",
            "è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯è®¡ç®—æœºç§‘å­¦çš„é‡è¦åˆ†æ”¯ã€‚",
            "åˆ†è¯æ˜¯æ–‡æœ¬å¤„ç†çš„ç¬¬ä¸€æ­¥ã€‚",
        ]

        corpus = []
        for i in range(size):
            corpus.append(texts[i % len(texts)])
        return corpus

    def _create_zero_tokenizer(self):
        """åˆ›å»ºZero Tokenizerå®ä¾‹"""
        if not ZERO_AVAILABLE:
            return None

        if self.algorithm == 'bpe':
            return ZeroBPE()
        elif self.algorithm == 'bbpe':
            return ZeroBBPE()
        elif self.algorithm == 'unigram':
            return ZeroUnigram()
        elif self.algorithm == 'wordpiece':
            return ZeroWordPiece()
        else:
            raise ValueError(f"æœªçŸ¥ç®—æ³•: {self.algorithm}")

    def _create_hf_tokenizer(self):
        """åˆ›å»ºHuggingFace Tokenizerå®ä¾‹"""
        if not HF_AVAILABLE:
            return None, None

        if self.algorithm == 'bpe':
            tokenizer = Tokenizer(models.BPE())
            tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()
            trainer = trainers.BpeTrainer(
                vocab_size=self.vocab_size,
                special_tokens=["[UNK]"]
            )
        elif self.algorithm == 'bbpe':
            tokenizer = Tokenizer(models.BPE())
            tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()
            trainer = trainers.BpeTrainer(
                vocab_size=self.vocab_size,
                special_tokens=["[UNK]"]
            )
        elif self.algorithm == 'unigram':
            tokenizer = Tokenizer(models.Unigram())
            tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()
            trainer = trainers.UnigramTrainer(
                vocab_size=self.vocab_size,
                special_tokens=["[UNK]"]
            )
        elif self.algorithm == 'wordpiece':
            tokenizer = Tokenizer(models.WordPiece(unk_token="[UNK]"))
            tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()
            trainer = trainers.WordPieceTrainer(
                vocab_size=self.vocab_size,
                special_tokens=["[UNK]"]
            )
        else:
            raise ValueError(f"æœªçŸ¥ç®—æ³•: {self.algorithm}")

        return tokenizer, trainer

    def benchmark_training(self) -> tuple:
        """åŸºå‡†æµ‹è¯•ï¼šè®­ç»ƒé€Ÿåº¦"""
        print("\n" + "="*70)
        print(f"ğŸ“Š è®­ç»ƒé€Ÿåº¦åŸºå‡†æµ‹è¯• - {self.ALGORITHMS[self.algorithm]}")
        print("="*70)

        tokenizer_zero = None
        tokenizer_hf = None

        # Zero Tokenizer è®­ç»ƒ
        if ZERO_AVAILABLE:
            times = []
            for i in range(self.iterations):
                tokenizer = self._create_zero_tokenizer()

                start = time.perf_counter()
                tokenizer.train(self.train_corpus, self.vocab_size)
                elapsed = time.perf_counter() - start

                times.append(elapsed)
                print(f"  Zero Tokenizer ç¬¬{i+1}æ¬¡: {elapsed*1000:.2f}ms")

            avg_time = sum(times) / len(times)
            self.results['zero_training'] = {
                'avg_ms': avg_time * 1000,
                'min_ms': min(times) * 1000,
                'max_ms': max(times) * 1000,
            }
            print(f"  âœ… Zero Tokenizer å¹³å‡: {avg_time*1000:.2f}ms")

            # ä¿ç•™è®­ç»ƒå¥½çš„tokenizer
            tokenizer_zero = self._create_zero_tokenizer()
            tokenizer_zero.train(self.train_corpus, self.vocab_size)

        # HuggingFace Tokenizer è®­ç»ƒ
        if HF_AVAILABLE:
            times = []
            for i in range(self.iterations):
                tokenizer, trainer = self._create_hf_tokenizer()

                start = time.perf_counter()
                tokenizer.train_from_iterator(self.train_corpus, trainer=trainer)
                elapsed = time.perf_counter() - start

                times.append(elapsed)
                print(f"  HF Tokenizer ç¬¬{i+1}æ¬¡: {elapsed*1000:.2f}ms")

            avg_time = sum(times) / len(times)
            self.results['hf_training'] = {
                'avg_ms': avg_time * 1000,
                'min_ms': min(times) * 1000,
                'max_ms': max(times) * 1000,
            }
            print(f"  âœ… HF Tokenizer å¹³å‡: {avg_time*1000:.2f}ms")

            # ä¿ç•™è®­ç»ƒå¥½çš„tokenizer
            tokenizer_hf, trainer = self._create_hf_tokenizer()
            tokenizer_hf.train_from_iterator(self.train_corpus, trainer=trainer)

        return tokenizer_zero, tokenizer_hf

    def benchmark_dict_init(self) -> Optional[float]:
        """åŸºå‡†æµ‹è¯•ï¼šå­—å…¸åˆå§‹åŒ–ï¼ˆä»…Unigramå’ŒWordPieceï¼‰"""
        if self.algorithm not in ['unigram', 'wordpiece']:
            return None

        if not self.dict_path.exists():
            print(f"  âš ï¸  å­—å…¸æ–‡ä»¶ä¸å­˜åœ¨: {self.dict_path}")
            return None

        print("\n" + "="*70)
        print(f"ğŸ“Š å­—å…¸åˆå§‹åŒ–é€Ÿåº¦æµ‹è¯• - {self.ALGORITHMS[self.algorithm]}")
        print("="*70)

        if ZERO_AVAILABLE:
            times = []
            for i in range(self.iterations):
                start = time.perf_counter()
                tokenizer = self._create_zero_tokenizer()
                elapsed = time.perf_counter() - start

                times.append(elapsed)
                print(f"  Zero Tokenizer ç¬¬{i+1}æ¬¡: {elapsed*1000:.2f}ms")

            avg_time = sum(times) / len(times)
            self.results['zero_dict_init'] = {
                'avg_ms': avg_time * 1000,
                'min_ms': min(times) * 1000,
                'max_ms': max(times) * 1000,
            }
            print(f"  âœ… Zero Tokenizer å¹³å‡: {avg_time*1000:.2f}ms")
            return avg_time

        return None

    def benchmark_encoding_single(self, tokenizer_zero=None, tokenizer_hf=None) -> None:
        """åŸºå‡†æµ‹è¯•ï¼šå•æ¡ç¼–ç é€Ÿåº¦"""
        print("\n" + "="*70)
        print(f"ğŸ“Š å•æ¡ç¼–ç é€Ÿåº¦æµ‹è¯• - {self.ALGORITHMS[self.algorithm]}")
        print("="*70)

        test_texts = [
            "The quick brown fox jumps over the lazy dog.",
            "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œã€‚",
            "Mixed English and ä¸­æ–‡ content.",
        ]

        for test_text in test_texts:
            print(f"\n  æµ‹è¯•æ–‡æœ¬: '{test_text[:50]}...'")

            if ZERO_AVAILABLE and tokenizer_zero:
                times = []
                for _ in range(100):
                    start = time.perf_counter()
                    _ = tokenizer_zero.encode(test_text)
                    elapsed = time.perf_counter() - start
                    times.append(elapsed)

                avg_time = sum(times) / len(times)
                print(f"    Zero Tokenizer: {avg_time*1000:.4f}ms")

            if HF_AVAILABLE and tokenizer_hf:
                times = []
                for _ in range(100):
                    start = time.perf_counter()
                    _ = tokenizer_hf.encode(test_text)
                    elapsed = time.perf_counter() - start
                    times.append(elapsed)

                avg_time = sum(times) / len(times)
                print(f"    HF Tokenizer: {avg_time*1000:.4f}ms")

    def benchmark_encoding_batch(self, tokenizer_zero=None, tokenizer_hf=None) -> None:
        """åŸºå‡†æµ‹è¯•ï¼šæ‰¹é‡ç¼–ç é€Ÿåº¦"""
        print("\n" + "="*70)
        print(f"ğŸ“Š æ‰¹é‡ç¼–ç é€Ÿåº¦æµ‹è¯• - {self.ALGORITHMS[self.algorithm]}")
        print("="*70)

        batch_sizes = [10, 100, 1000]

        for batch_size in batch_sizes:
            print(f"\n  æ‰¹é‡å¤§å°: {batch_size}")
            test_batch = self.test_texts[:batch_size]

            if ZERO_AVAILABLE and tokenizer_zero:
                # æ£€æŸ¥æ˜¯å¦æœ‰encode_batchæ–¹æ³•
                if hasattr(tokenizer_zero, 'encode_batch'):
                    start = time.perf_counter()
                    _ = tokenizer_zero.encode_batch(test_batch)
                    elapsed = time.perf_counter() - start
                    throughput = batch_size / elapsed
                    print(f"    Zero Tokenizer (å¹¶è¡Œ): {throughput:.0f} æ¡/ç§’ ({elapsed*1000:.2f}ms)")
                else:
                    # ä¸²è¡Œå¤„ç†
                    start = time.perf_counter()
                    for text in test_batch:
                        _ = tokenizer_zero.encode(text)
                    elapsed = time.perf_counter() - start
                    throughput = batch_size / elapsed
                    print(f"    Zero Tokenizer (ä¸²è¡Œ): {throughput:.0f} æ¡/ç§’ ({elapsed*1000:.2f}ms)")

            if HF_AVAILABLE and tokenizer_hf:
                start = time.perf_counter()
                _ = tokenizer_hf.encode_batch(test_batch)
                elapsed = time.perf_counter() - start
                throughput = batch_size / elapsed
                print(f"    HF Tokenizer: {throughput:.0f} æ¡/ç§’ ({elapsed*1000:.2f}ms)")

    def benchmark_decoding(self, tokenizer_zero=None, tokenizer_hf=None) -> None:
        """åŸºå‡†æµ‹è¯•ï¼šè§£ç é€Ÿåº¦"""
        print("\n" + "="*70)
        print(f"ğŸ“Š è§£ç é€Ÿåº¦æµ‹è¯• - {self.ALGORITHMS[self.algorithm]}")
        print("="*70)

        test_text = "The quick brown fox jumps over the lazy dog."

        if ZERO_AVAILABLE and tokenizer_zero:
            tokens = tokenizer_zero.encode(test_text)

            times = []
            for _ in range(100):
                start = time.perf_counter()
                _ = tokenizer_zero.decode(tokens)
                elapsed = time.perf_counter() - start
                times.append(elapsed)

            avg_time = sum(times) / len(times)
            print(f"  âœ… Zero Tokenizer: {avg_time*1000:.4f}ms (å¹³å‡)")

        if HF_AVAILABLE and tokenizer_hf:
            encoding = tokenizer_hf.encode(test_text)
            tokens = encoding.ids

            times = []
            for _ in range(100):
                start = time.perf_counter()
                _ = tokenizer_hf.decode(tokens)
                elapsed = time.perf_counter() - start
                times.append(elapsed)

            avg_time = sum(times) / len(times)
            print(f"  âœ… HF Tokenizer: {avg_time*1000:.4f}ms (å¹³å‡)")

    def run_all_benchmarks(self) -> None:
        """è¿è¡Œæ‰€æœ‰åŸºå‡†æµ‹è¯•"""
        print("="*70)
        print(f"ğŸš€ å®Œæ•´æ€§èƒ½å¯¹æ¯”åŸºå‡†æµ‹è¯• - {self.ALGORITHMS[self.algorithm]}")
        print("="*70)
        print(f"ç®—æ³•: {self.ALGORITHMS[self.algorithm]}")
        print(f"è¯æ±‡è¡¨å¤§å°: {self.vocab_size}")
        print(f"è¿­ä»£æ¬¡æ•°: {self.iterations}")
        print(f"è®­ç»ƒè¯­æ–™: {len(self.train_corpus)} æ¡")
        print(f"æµ‹è¯•æ–‡æœ¬: {len(self.test_texts)} æ¡")

        # 1. å­—å…¸åˆå§‹åŒ–æµ‹è¯•ï¼ˆå¦‚æœé€‚ç”¨ï¼‰
        self.benchmark_dict_init()

        # 2. è®­ç»ƒæµ‹è¯•
        tokenizer_zero, tokenizer_hf = self.benchmark_training()

        # 3. å•æ¡ç¼–ç æµ‹è¯•
        self.benchmark_encoding_single(tokenizer_zero, tokenizer_hf)

        # 4. æ‰¹é‡ç¼–ç æµ‹è¯•
        self.benchmark_encoding_batch(tokenizer_zero, tokenizer_hf)

        # 5. è§£ç æµ‹è¯•
        self.benchmark_decoding(tokenizer_zero, tokenizer_hf)

    def save_results(self, output_file: str) -> None:
        """ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶"""
        output_path = Path(__file__).parent / output_file

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")


def main():
    parser = argparse.ArgumentParser(
        description="Zero Tokenizer vs HuggingFace Tokenizers å®Œæ•´æ€§èƒ½å¯¹æ¯”"
    )
    parser.add_argument(
        '--algorithm',
        type=str,
        choices=['bpe', 'bbpe', 'unigram', 'wordpiece', 'all'],
        default='bpe',
        help='æµ‹è¯•çš„ç®—æ³• (é»˜è®¤: bpeï¼Œallè¡¨ç¤ºæµ‹è¯•æ‰€æœ‰ç®—æ³•)'
    )
    parser.add_argument(
        '--vocab-size',
        type=int,
        default=1000,
        help='è¯æ±‡è¡¨å¤§å° (é»˜è®¤: 1000)'
    )
    parser.add_argument(
        '--iterations',
        type=int,
        default=5,
        help='è®­ç»ƒè¿­ä»£æ¬¡æ•° (é»˜è®¤: 5)'
    )

    args = parser.parse_args()

    if not ZERO_AVAILABLE:
        print("\nâŒ é”™è¯¯: Zero Tokenizeræœªå®‰è£…")
        print("   è¯·å…ˆè¿è¡Œ: maturin develop")
        sys.exit(1)

    if not HF_AVAILABLE:
        print("\nâš ï¸  è­¦å‘Š: HuggingFace tokenizersæœªå®‰è£…")
        print("   å°†åªæµ‹è¯•Zero Tokenizeræ€§èƒ½")
        print("   è¦è¿›è¡Œå¯¹æ¯”æµ‹è¯•ï¼Œè¯·è¿è¡Œ: pip install tokenizers")
        print()

    # æµ‹è¯•æ‰€æœ‰ç®—æ³•æˆ–å•ä¸ªç®—æ³•
    algorithms_to_test = ['bpe', 'bbpe', 'unigram', 'wordpiece'] if args.algorithm == 'all' else [args.algorithm]

    for algo in algorithms_to_test:
        print("\n" + "â–ˆ"*70)
        print(f"  å¼€å§‹æµ‹è¯•: {ComprehensiveBenchmark.ALGORITHMS[algo]}")
        print("â–ˆ"*70)

        benchmark = ComprehensiveBenchmark(
            algorithm=algo,
            vocab_size=args.vocab_size,
            iterations=args.iterations
        )
        benchmark.run_all_benchmarks()
        benchmark.save_results(f"benchmark_{algo}_results.json")

        print("\n" + "="*70)
        print(f"âœ… {ComprehensiveBenchmark.ALGORITHMS[algo]} æµ‹è¯•å®Œæˆï¼")
        print("="*70 + "\n")


if __name__ == "__main__":
    main()
